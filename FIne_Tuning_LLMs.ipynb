{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNwU0KTPHZNAnqDA9CRPj66",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/buriihenry/Fine-Tuning-LLMs---Llama2/blob/master/FIne_Tuning_LLMs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9GB0ife3gPE",
        "outputId": "5772f825-70e3-4af1-b272-b21e5d83f4fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradientai\n",
            "  Downloading gradientai-1.1.0-py3-none-any.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aenum>=3.1.11 (from gradientai)\n",
            "  Downloading aenum-3.1.15-py3-none-any.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<2.0.0,>=1.10.5 in /usr/local/lib/python3.10/dist-packages (from gradientai) (1.10.13)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from gradientai) (2.8.2)\n",
            "Requirement already satisfied: urllib3>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from gradientai) (2.0.6)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.0.0,>=1.10.5->gradientai) (4.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->gradientai) (1.16.0)\n",
            "Installing collected packages: aenum, gradientai\n",
            "Successfully installed aenum-3.1.15 gradientai-1.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install gradientai --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['GRADIENT_ACCESS_TOKEN'] = \"llGxyzBstszOudS02yAj1VpOqZBog5vl\"\n",
        "os.environ['GRADIENT_WORKSPACE_ID'] = \"ccafe93f-eabd-4805-aa09-605099f2364b_workspace\""
      ],
      "metadata": {
        "id": "VZ6CNs3O4fb-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gradientai import Gradient\n",
        "def main():\n",
        "  with Gradient() as gradient:\n",
        "    base_model = gradient.get_base_model(base_model_slug=\"nous-hermes2\") # Using our Base model which we are going to fine tune ontop of\n",
        "    #nous-hermes2 is a fine tuned version of Llama 2\n",
        "\n",
        "    new_model_adapter = base_model.create_model_adapter(\n",
        "        name=\"test model 3\"\n",
        "    )\n",
        "    print(f\"Created model adapter with id{new_model_adapter.id}\")\n",
        "    sample_query = \"### Instruction: Who is Henry Burii? \\n\\### Response:\"\n",
        "    print(f\"Asking: {sample_query}\")\n"
      ],
      "metadata": {
        "id": "5uRZ0BAO9PsA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}