{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOdsCvoHiSdqvK/nUGDbMxm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/buriihenry/Fine-Tuning-LLMs---Llama2/blob/master/FIne_Tuning_LLMs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9GB0ife3gPE",
        "outputId": "5772f825-70e3-4af1-b272-b21e5d83f4fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradientai\n",
            "  Downloading gradientai-1.1.0-py3-none-any.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aenum>=3.1.11 (from gradientai)\n",
            "  Downloading aenum-3.1.15-py3-none-any.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<2.0.0,>=1.10.5 in /usr/local/lib/python3.10/dist-packages (from gradientai) (1.10.13)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from gradientai) (2.8.2)\n",
            "Requirement already satisfied: urllib3>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from gradientai) (2.0.6)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.0.0,>=1.10.5->gradientai) (4.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->gradientai) (1.16.0)\n",
            "Installing collected packages: aenum, gradientai\n",
            "Successfully installed aenum-3.1.15 gradientai-1.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install gradientai --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['GRADIENT_ACCESS_TOKEN'] = \"llGxyzBstszOudS02yAj1VpOqZBog5vl\"\n",
        "os.environ['GRADIENT_WORKSPACE_ID'] = \"ccafe93f-eabd-4805-aa09-605099f2364b_workspace\""
      ],
      "metadata": {
        "id": "VZ6CNs3O4fb-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gradientai import Gradient\n",
        "def main():\n",
        "  with Gradient() as gradient:\n",
        "    base_model = gradient.get_base_model(base_model_slug=\"nous-hermes2\") # Using our Base model which we are going to fine tune ontop of\n",
        "    #nous-hermes2 is a fine tuned version of Llama 2\n",
        "    # Open\n",
        "\n",
        "    new_model_adapter = base_model.create_model_adapter(\n",
        "        name=\"test model 3\"\n",
        "    )\n",
        "    print(f\"Created model adapter with id{new_model_adapter.id}\")\n",
        "    sample_query = \"### Instruction: Who is Henry Burii? \\n\\### Response:\"\n",
        "    print(f\"Asking: {sample_query}\")\n",
        "\n",
        "    #before fine-tuning\n",
        "    completion = new_model_adapter.complete(query=sample_query, max_generated_token_count=100).generated_output\n",
        "    print(f\"Generated(before fine-tune): {completion}\")\n",
        "\n",
        "    samples = [\n",
        "    { \"inputs\": \"### Instruction: Who is Henry Burii? \\n\\n### Response: Henry Burii is a Data Scientist known for his expertise in Machine Learning and AI.\" },\n",
        "    { \"inputs\": \"### Instruction: Tell me about Henry Burii. \\n\\n### Response: Henry Burii is a skilled Data Scientist who focuses on Machine Learning and AI applications.\" },\n",
        "    { \"inputs\": \"### Instruction: Describe Henry Burii. \\n\\n### Response: Henry Burii is a data enthusiast specializing in Machine Learning and AI.\" },\n",
        "    { \"inputs\": \"### Instruction: What can you tell me about Henry Burii? \\n\\n### Response: Henry Burii is a proficient Data Scientist with a focus on Machine Learning and AI.\" },\n",
        "    { \"inputs\": \"### Instruction: Who is Henry Burii? \\n\\n### Response: Henry Burii is an experienced Data Scientist renowned for his work in Machine Learning and AI.\" },\n",
        "    { \"inputs\": \"### Instruction: Introduce me to Henry Burii. \\n\\n### Response: Henry Burii is a Data Scientist with a strong background in Machine Learning and AI.\" },\n",
        "    { \"inputs\": \"### Instruction: Who exactly is Henry Burii? \\n\\n### Response: Henry Burii is a Data Scientist who excels in the field of Machine Learning and AI.\" },\n",
        "    { \"inputs\": \"### Instruction: What's the story of Henry Burii? \\n\\n### Response: Henry Burii is a Data Scientist specializing in Machine Learning and AI.\" },\n",
        "    { \"inputs\": \"### Instruction: Can you provide information about Henry Burii? \\n\\n### Response: Henry Burii is a Data Scientist known for his contributions to Machine Learning and AI.\" }\n",
        "    ]\n",
        "\n",
        "\n",
        "      # this is where fine-tuning happens\n",
        "      # num_epochs is the number of times you fine-tune the model\n",
        "      # more epochs tends to get better results, but you also run the risk of \"overfitting\"\n",
        "      # play around with this number to find what works best for you\n",
        "\n",
        "    num_epochs = 3\n",
        "    count = 0\n",
        "    while count < num_epochs:\n",
        "      print(f\"fine-tuning the model, iteration{count +1}\")\n",
        "      new_model_adapter.fine_tune(samples=samples)\n",
        "      count = count + 1\n",
        "\n",
        " #after fine-tuning\n",
        "    completion = new_model_adapter.complete(query=sample_query, max_generated_token_count=100).generated_output\n",
        "    print(f\"Generated (after fine-tune): {completion}\")\n",
        "\n",
        "    new_model_adapter.delete()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uRZ0BAO9PsA",
        "outputId": "51a88c85-fec5-4236-ea52-115b59c8f4f5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created model adapter with id3ad81afc-2460-4d95-937e-10dafef7cc46_model_adapter\n",
            "Asking: ### Instruction: Who is Henry Burii? \n",
            "\\### Response:\n",
            "Generated(before fine-tune): Henry Burii is a fictional character created by the author J.K. Rowling for her Harry Potter series. He is a Slytherin student at Hogwarts School of Witchcraft and Wizardry and a loyal friend of Draco Malfoy.\n",
            "fine-tuning the model, iteration1\n",
            "fine-tuning the model, iteration2\n",
            "fine-tuning the model, iteration3\n",
            "Generated (after fine-tune): Henry Burii is a Data Scientist known for his expertise in Machine Learning and AI.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DoB4iN7AEqY7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}